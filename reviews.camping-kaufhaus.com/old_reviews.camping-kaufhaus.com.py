from agent import *from models.products import *import simplejsonimport HTMLParserimport reh = HTMLParser.HTMLParser()XCAT = ['SALE', 'Camping-Welten']def remove_emoji(string):    emoji_pattern = re.compile("["                               u"\U0001F600-\U0001F64F"  # emoticons                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs                               u"\U0001F680-\U0001F6FF"  # transport & map symbols                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)                               u"\U00002500-\U00002BEF"  # chinese char                               u"\U00002702-\U000027B0"                               u"\U00002702-\U000027B0"                               u"\U000024C2-\U0001F251"                               u"\U0001f926-\U0001f937"                               u"\U00010000-\U0010ffff"                               u"\u2640-\u2642"                               u"\u2600-\u2B55"                               u"\u200d"                               u"\u23cf"                               u"\u23e9"                               u"\u231a"                               u"\ufe0f"  # dingbats                               u"\u3030"                               u"&#\d+;"  # HTML entities                               "]+", flags=re.UNICODE)    return emoji_pattern.sub(r'', string)def run(context, session):    session.sessionbreakers = [SessionBreak(max_requests=5000)]    session.queue(Request('https://www.camping-kaufhaus.com/', use="curl", force_charset='utf-8', max_age=0), process_frontpage, dict())def process_frontpage(data, context, session):    cats = data.xpath('//div[@class="menu--container"]')    for cat in cats:        name = cat.xpath('div[@class="button-container"]/a/span/text()').string()        if name and name not in XCAT:            cats1 = cat.xpath('.//ul/li[contains(@class, "list-item")]/a')            for cat1 in cats1:                name1 = cat1.xpath('text()').string()                url = cat1.xpath('@href').string()                session.queue(Request(url, use="curl", force_charset='utf-8', max_age=0), process_category, dict(cat=name+'|'+name1))def process_category(data, context, session):    subcats = data.xpath('//div[@class="framemenu--list"]//a[contains(@class, "item-link")]')    if not subcats:        process_prodlist(data, context, session)        return    for subcat in subcats:        name = subcat.xpath('text()').string()        url = subcat.xpath('@href').string()        session.queue(Request(url, use="curl", force_charset='utf-8', max_age=0), process_category, dict(cat=context['cat']+'|'+name))def process_prodlist(data, context, session):    prods = data.xpath('//div[@class="product--info"]')    for prod in prods:        name = prod.xpath('a[@class="product--title"]/text()').string()        url = prod.xpath('a[@class="product--title"]/@href').string().split('?')[0]        revs_cnt = prod.xpath('div[contains(@class, "reviews")]/input/@data-count').string()        if revs_cnt and int(revs_cnt.strip('( )')) > 0:            session.queue(Request(url, use="curl", force_charset='utf-8', max_age=0), process_product, dict(context, name=name, url=url))    next_url = data.xpath('//div[contains(@class, "listing--paging")]/a[regexp:test(@title, "Nächste", "i")]/@href').string()    if next_url:        session.queue(Request(next_url, use="curl", force_charset='utf-8', max_age=0), process_prodlist, context)def process_product(data, context, session):    product = Product()    product.name = context['name']    product.url = context['url']    product.category = context['cat']    product.manufacturer = data.xpath('//meta[@itemprop="brand"]/@content').string()    product.ssid = data.xpath('//span[@itemprop="sku"]/text()').string()    product.sku = data.xpath('//div/input/@data-sku').string()    ean = data.xpath('//script[contains(., "productEAN")]/text()').string()    if ean:        ean = ean.split('"productEAN":"')[-1].split('"', 1)[0]        product.properties.append(ProductProperty(type='id.ean', value=ean))    mpn = data.xpath('//div[contains(@class, "suppliernr")]/span[contains(@class, "value")]/text()').string()    if mpn:        mpn = mpn.split('+')[0]        if len(mpn) > 7:            product.properties.append(ProductProperty(type='id.manufacturer', value=mpn))    revs_url = 'https://api.reviews.io/timeline/data?type=product_review&store=www.camping-kaufhaus.com&page=1&per_page=15&sku=%s&lang=de' % product.sku    session.do(Request(revs_url, use="curl", force_charset='utf-8', max_age=0), process_reviews, dict(product=product))def process_reviews(data, context, session):    product = context["product"]    revs_json = simplejson.loads(data.content)    revs = revs_json.get("timeline", [])    for rev in revs:        rev = rev.get('_source', {})        if rev.get('imported_from') or not rev.get('type') or rev['type'] != 'product_review':            continue        review = Review()        review.type = "user"        review.url = product.url        review.ssid = str(rev['_id']).split('-')[-1]        title = rev.get('review_title')        if title:            review.title = h.unescape(remove_emoji(title)).replace('\r', '').replace('\n', ' ').strip(' .+*,')        date = rev.get('date_updated', rev.get('date_created'))        if date:            review.date = date.split()[0]        author = rev.get('author')        if author:            author = h.unescape(remove_emoji(author)).strip(' .+*,')            if author:                review.authors.append(Person(name=author, ssid=author))        is_verified = rev.get('order_id')        if is_verified:            review.add_property(type='is_verified_buyer', value=True)        hlp_yes = rev.get('helpful')        if hlp_yes and hlp_yes > 0:            review.add_property(type='helpful_votes', value=int(hlp_yes))        grade_names = {6326: 'Qualität', 6327: 'Handling'}        grades = rev.get('additional_ratings', [])        for grade in grades:            grade_name = grade_names.get(grade['rating_id'])            grade_value = grade.get('rating')            if grade_name and grade_value:                review.grades.append(Grade(name=grade_name, value=float(grade_value), best=5.0))        grade_overall = rev.get('rating')        if grade_overall:            review.grades.append(Grade(type="overall", value=float(grade_overall), best=5.0))        excerpt = rev.get('comments')        if excerpt:            excerpt = h.unescape(remove_emoji(excerpt).replace('\r', '').replace('\n', ' ')).strip(' +*,').lstrip('.')            if excerpt:                review.add_property(type="excerpt", value=excerpt)                product.reviews.append(review)    offset = context.get('offset', 0) + 15    revs_cnt = revs_json.get('stats', {}).get('review_count')    if revs_cnt and offset < int(revs_cnt):        next_page = context.get('page', 1) + 1        revs_url = 'https://api.reviews.io/timeline/data?type=product_review&store=www.camping-kaufhaus.com&page=%s&per_page=15&sku=%s&lang=de' % (next_page, product.sku)        session.do(Request(revs_url, use="curl", force_charset='utf-8', max_age=0), process_reviews, dict(context, offset=offset, page=next_page))    elif product.reviews:        session.emit(product)