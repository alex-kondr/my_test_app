from agent import *from models.products import *import simplejsonXCAT = ['Buying Guides', 'Gift Guide']def run(context, session):    session.sessionbreakers = [SessionBreak(max_requests=3000)]    session.queue(Request('https://www.theverge.com/reviews/', use='curl', max_age=0), process_catlist, {})def process_catlist(data, context, session):    cats = data.xpath('//ul[@class="flex flex-wrap"]/li/a')    for cat in cats:        name = cat.xpath('text()').string()        url = cat.xpath('@href').string()        if url and name not in XCAT:            url = url + '/archives/1'            session.queue(Request(url, use='curl', max_age=0), process_revlist, dict(cat=name))def process_revlist(data, context, session):    revs = data.xpath('//a[contains(@class, "group hover")]')    for rev in revs:        title = rev.xpath('@aria-label').string()        url = rev.xpath('@href').string()        if '23302947/philips' in url or '23311283/philips' in url:            continue        if title and url:            url = url.split('?')[0]            session.queue(Request(url, use='curl', max_age=0), process_review, dict(context, title=title, url=url))    next_url = data.xpath('//a[@rel="next"][span[contains(text(), "Next")]]/@href').string()    if next_url:        session.queue(Request(next_url, use='curl', max_age=0), process_revlist, dict(context))def process_review(data, context, session):    json = data.xpath('''//script[@type="application/ld+json"][contains(., '"@type":"Product"')]//text()''').string()    prod_data = dict()    if json:        prod_data = simplejson.loads(json)    product = Product()    review = Review()    product.name = prod_data.get('name')    manufacturer = prod_data.get('brand')    if manufacturer:        product.manufacturer = manufacturer.get('name')    author = prod_data.get('review', {}).get('author')    if author:        author_name = author[0].get('name')        author_url = author[0].get('url')        if author_name and author_url:            review.authors.append(Person(name=author_name, profile_url=author_url, ssid=author_name))        elif author_name:            review.authors.append(Person(name=author_name, ssid=author_name))    grade_overall = prod_data.get('review', {}).get('reviewRating')    if grade_overall:        value = grade_overall.get('ratingValue')        if value:            review.grades.append(Grade(type='overall', value=float(value), best=10))    if not product.name:        product.name = context['title'].split('review:')[0].split('â€”')[0].split(' review')[0].split(' Review')[0].split(' on the ')[-1]    product.url = context['url']    product.ssid = context['url'].split('/')[-2]    if product.ssid.isalpha() == True:        product.ssid = context['url'].split('/')[-1]    product.category = context['cat']    review.title = context['title']    review.url = product.url    review.ssid = product.ssid    review.type = 'pro'    date = data.xpath('//meta[@property="article:published_time"]/@content').string()    if date:        review.date = date.split('T')[0]    if not review.authors:        author = data.xpath('//a[contains(@href, "author")]').first()        if not author:            author = data.xpath('//a[contains(@href, "users")]').first()        if author:            author_name = author.xpath('text()').string()            author_url = author.xpath('@href').string()            if author_name and author_url:                review.authors.append(Person(name=author_name, profile_url=author_url, ssid=author_name))            elif author_name:                review.authors.append(Person(name=author_name, ssid=author_name))    if not review.grades:        grade_overall = data.xpath('//span[@class="score-number"]/text()').string()        if not grade_overall:            grade_overall = data.xpath('//span[contains(., "Verge Score")]/preceding-sibling::span/text()').string()        if grade_overall and grade_overall.isdigit():            review.grades.append(Grade(type='overall', value=float(grade_overall), best=10))    pros = data.xpath('//ul[@class="tally good"]/li//text()')    if not pros:        pros = data.xpath('//h3[contains(., "The Good")]/following-sibling::ul/li//text()')    if pros:        for pro in pros:            review.add_property(type='pros', value=pro.string())    cons = data.xpath('//ul[@class="tally bad"]/li//text()')    if not cons:        cons = data.xpath('//h3[contains(., "The Bad")]/following-sibling::ul/li//text()')    if cons:        for con in cons:            review.add_property(type='cons', value=con.string())    summary = data.xpath('//p[@class="intro"]//text()').string(multiple=True)    if not summary:        summary = data.xpath('//h2[contains(@class, "duet--article--dangerously")]/text()').string()    if not summary:        summary = data.xpath('//h2[contains(@class, "inline selection:")]/span/text()').string()    if not summary:        summary = data.xpath('//meta[@name="description"]/@content').string()    if summary:        review.add_property(type='summary', value=summary)    excerpt = data.xpath('//div[@class="m-row curtain"]//p[not(.//@class="caption")]//text()').string(multiple=True)    if not excerpt:        excerpt = data.xpath('//div[contains(@class, "article-body-component")]//p[not(contains(.//em/text(), "Photography by"))][not(contains(., "Exclusive first looks at"))]//text() | //h3[not(.//a)][not(contains(@class, "leading-140 tracking-12"))][not(contains(@class, "duet--article--dangerously-set-cms-markup"))]//text()').string(multiple=True)    if excerpt:        if summary:            excerpt = excerpt.replace(summary, '')        review.add_property(type='excerpt', value=excerpt)        product.reviews.append(review)        session.emit(product)