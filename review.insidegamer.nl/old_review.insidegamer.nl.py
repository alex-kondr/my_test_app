from agent import *from models.products import *import reCAT = ['Pc-gaming', 'PlayStation', 'Nintendo', 'Xbox']def run(context, session):    session.queue(Request('https://inside.gamer.nl/category/user-reviews/'), process_revlist, dict())def process_revlist(data, context, session):    revs = data.xpath('//h3[@class="g1-delta g1-delta-1st entry-title"]/a')    for rev in revs:        title = rev.xpath("text()").string()        url = rev.xpath("@href").string()        session.queue(Request(url), process_review, dict(title=title, url=url))    next_url = data.xpath('//link[@rel="next"]/@href').string()    if next_url:        session.queue(Request(next_url), process_revlist, dict())def process_review(data, context, session):    if "mini-reviews" in context["title"].lower():        process_reviews(data, context, session)        return    product = Product()    product.name = context['title'].split("Review: ")[-1].split("REVIEW: ")[-1].split(" review – ")[0].split(" Review – ")[0].split('(')[0].split('Video: ')[-1].split("Honest Opinions – ")[-1].split('Mini review')[-1].strip(': ')    title = re_search_once(r'Mini-Reviews #\d+:(.*)', product.name)    if title:        product.name = title    product.url = context['url']    product.ssid = context['url'].split('/')[-2]    platforms = data.xpath("//meta[@property='article:section']/@content")    product.category = 'Games'    for platform in platforms:        platform = platform.string()        if platform in CAT:            product.category += '/' + platform    product.category = product.category.replace('/', '|', 1)    review = Review()    review.title = context['title']    review.url = context['url']    review.ssid = product.ssid    review.type = 'pro'    date = data.xpath("//time/@datetime").string()    if date:        review.date = date.split('T')[0]    author = data.xpath('//span[@itemprop="author"]//a[@rel="author"]').first()    if author:        author_name = author.xpath('@title').string().split(' by ')[-1]        author_url = author.xpath('@href').string()        if author_name and author_url:            review.authors.append(Person(name=author_name, profile_url=author_url, ssid=author_name))        elif author_name:            review.authors.append(Person(name=author_name, ssid=author_name))    overall = data.xpath('''//div[@itemprop='articleBody']/p[regexp:test(., '^\d+(\.\d)?(,\d)?( ?\/ ?\d+)?$|^(eind)?cijfer:|score:|score;', 'i')]//text()''').string()    if overall == 'Cijfer:':        overall = data.xpath('''//div[@itemprop='articleBody']/p[regexp:test(., '^\d+(\.\d)?(,\d)?( ?\/ ?\d+)?$|^(eind)?cijfer:|score:|score;', 'i')]//text()''').string(multiple=True)    if not overall:        overall = data.xpath('//div[@itemprop="articleBody"]//p[contains(., "Eindcijfer")]//text()').string(multiple=True)    if not overall:        overall = data.xpath('//p[contains(., "Eincijfer")][contains(., ":")]/following-sibling::p[1]//text()').string()    if overall:        overall = overall.split(':')[-1].split('; ')[-1].split('/')[0].split('Eindcijfer ')[-1].replace('-', '').replace(',', '.').strip()        best = 100.0        if float(overall) <= 10:            best = 10.0        review.grades.append(Grade(type="overall", value=float(overall), best=best))    pros = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(., '^\+', 'i')]/br/following-sibling::text()")    if not pros:        pros = data.xpath("//div[@itemprop='articleBody']/ul/li[regexp:test(., 'pluspunten:', 'i')]/*[1][self::br]/following-sibling::text()")    if not pros:        pros = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), '^\+')]/text()")    if not pros:        pros = [item.string().strip() for item in data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), 'score:', 'i')][regexp:test(., '\+|–')]/*[1][self::br]/following-sibling::text()")]        if pros:            index = len(pros)            if '–' in pros:                index = pros.index('–')            pros = pros[0:index]    if not pros:        pros = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(., 'pluspunten')]/following-sibling::ul//text()")    for pro in pros:        if not (type(pro) == str or type(pro) == unicode):            pro = pro.string().strip('.… ')        if pro.lower().strip() == 'minpunten':            break        pro = pro.split('+')[-1].strip('.… ')        if pro and any(True for letter in ['a', 'i', 'e', 'o', 'u', 'y'] if letter in pro):            review.add_property(type='pros', value=pro)    cons = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(., '^–', 'i')]/br/following-sibling::text()")    if not cons:        cons = data.xpath("//div[@itemprop='articleBody']/ul/li[regexp:test(., 'minpunten:', 'i')]/*[1][self::br]/following-sibling::text()")    if not cons:        cons = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), '^–')]/text()")    if not cons:        cons = [item.string().strip('.… ') for item in data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), 'score:', 'i')][regexp:test(., '\+|–')]/*[1][self::br]/following-sibling::text()")]        if cons:            index = len(cons)            if '–' in cons:                index = cons.index('–')            cons = cons[index:len(cons)]    if not cons:        cons = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(., 'minpunten', 'i')]/following-sibling::ul//text()")    for con in cons:        if not (type(con) == str or type(con) == unicode):            con = con.string().strip('. ')        con = con.split('–')[-1].strip('.… ')        if con and any(True for letter in ['a', 'i', 'e', 'o', 'u', 'y'] if letter in con):            review.add_property(type='cons', value=con)    summary = data.xpath("//div[@itemprop='articleBody']/*[1]/strong/text()").string()    if not summary:        summary = data.xpath("//div[@itemprop='articleBody']/*[1]/em/text()").string()    if not summary:        summary = data.xpath("//div[@itemprop='articleBody']/h2[regexp:test(., 'samenvatting', 'i')]/following-sibling::*[1]//text()").string(multiple=True)    if summary:        review.add_property(type='summary', value=summary)    conclusion = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), '^conclusie:?', 'i')]//text()").string(multiple=True)    if conclusion:        conclusion = conclusion.replace("Conclusie:", '').strip()    if not conclusion:        conclusion = data.xpath("//div[@itemprop='articleBody']/p[strong[regexp:test(., '^conclusie:?', 'i')]]/text()").string()    if not conclusion:        conclusion = data.xpath("//div[@itemprop='articleBody']/p[strong[regexp:test(., '^conclusie:?', 'i')]]/following-sibling::*[1]//text()").string(multiple=True)    if not conclusion:        conclusion = data.xpath("//div[@itemprop='articleBody']/p[regexp:test(text(), '^conclusie:?', 'i')]/following-sibling::*[1]//text()").string(multiple=True)    excerpt = data.xpath('//div[@itemprop="articleBody"]/span[@class="s2"]//text() | //div[@itemprop="articleBody"]/p[not(strong)][not(contains(., "Conclusie:")) and not(preceding-sibling::p[contains(., "Conclusie:")])]//text()').string(multiple=True)    if not excerpt:        excerpt = data.xpath('//div[@itemprop="articleBody"]//p[not(strong)][not(@class)][not(contains(., "Conclusie:")) and not(preceding-sibling::p[contains(., "Conclusie:")])]//text()').string(multiple=True)    if excerpt:        if summary:            excerpt = excerpt.replace(summary.strip(), '')        if conclusion:            excerpt = excerpt.replace(conclusion.strip(), '')            if conclusion.startswith('Conclusie:'):                conclusion = conclusion.replace("Conclusie:", '').strip()            review.add_property(type='conclusion', value=conclusion)        excerpt = excerpt.strip()        review.add_property(type='excerpt', value=excerpt)        product.reviews.append(review)        session.emit(product)def process_reviews(data, context, session):    names = []    name_data = context['title'].split(':')[-1]    if '–' in name_data and 'Echo Tokyo' not in name_data:        name_data = name_data.split('–')        main_part = name_data[0]        subs = re.split(r',|&', main_part)        for sub in subs:            names.append(sub)        if len(subs) == 1:            subs = re.split(r',|&', name_data[-1])            for sub in subs:                names.append(sub)    else:        name_data = re.split(r',|&', name_data)        for nd in name_data:            names.append(nd.strip())    platforms = data.xpath("//meta[@property='article:section']/@content")    elems = data.xpath('//div[@itemprop="articleBody"]/p[regexp:test(., "^conclusie:", "i")]')    for i, elem in enumerate(elems):        product = Product()        product.name = names[i]        product.url = context['url']        product.ssid = product.name.strip().lower().replace('–', '').replace(' ', '-').replace('--', '-')        product.category = 'Games'        for platform in platforms:            platform = platform.string()            if platform in CAT:                product.category += '/' + platform        product.category = product.category.replace('/', '|', 1)        review = Review()        review.title = product.name        review.url = context['url']        review.ssid = product.ssid        review.type = 'pro'        date = data.xpath("//time/@datetime").string()        if date:            review.date = date.split('T')[0]        author = data.xpath('//span[@itemprop="author"]//a[@rel="author"]').first()        if author:            author_name = author.xpath('@title').string().split(' by ')[-1]            author_url = author.xpath('@href').string()            if author_name and author_url:                review.authors.append(Person(name=author_name, profile_url=author_url, ssid=author_name))            elif author_name:                review.authors.append(Person(name=author_name, ssid=author_name))        overall = elem.xpath("following::*[self::p][regexp:test(., '^\d+\/\d+$')][1]/text()").string()        if overall:            value = float(overall.split('/')[0])            best = float(overall.split('/')[-1])            review.grades.append(Grade(type="overall", value=value, best=best))        pros = elem.xpath("following-sibling::*[2][self::p][regexp:test(text(), '^\+')]/text()")        for pro in pros:            pro = pro.string().replace('+', '').strip('.… ')            if pro == '–':                cons = [con.string() for con in pros]                for con in cons[cons.index('–')+1:]:                    review.add_property(type='cons', value=con)                break            elif pro:                review.add_property(type='pros', value=pro)        cons = elem.xpath("following-sibling::*[3][self::p][regexp:test(text(), '^–')]/text()")        for con in cons:            con = con.string().replace('–', '').strip('.… ')            if con:                review.add_property(type='cons', value=con)        conclusion = elem.xpath('text()').string(multiple=True)        if not conclusion:            conclusion = elem.xpath("following-sibling::*[1]/text()").string()        if conclusion:            review.add_property(type='conclusion', value=conclusion)        excerpt = ""        for e in reversed(elem.xpath("preceding-sibling::*")):            if e.xpath("self::p[regexp:test(., '^conclusie:', 'i')]") or e.xpath("preceding-sibling::*[1][self::p][regexp:test(., '^conclusie:', 'i')]"):                break            elif e.xpath("self::p[normalize-space()][not(regexp:test(text(), '^(\+|–)'))]"):                text = e.xpath("text()").string()                if text:                    excerpt = text + excerpt        if excerpt:            review.add_property(type='excerpt', value=excerpt)            product.reviews.append(review)            session.emit(product)