from agent import *from models.products import *def run(context, session):    session.sessionbreakers = [SessionBreak(max_requests=3000)]    session.queue(Request("https://geekweek.interia.pl/testy"), process_revlist, dict())def process_revlist(data, context, session):    revs = data.xpath('//h2[@class="tile-magazine-title"]')    for rev in revs:        title = rev.xpath('a/@title').string()        url = rev.xpath("a/@href").string()        if title and url:            session.queue(Request(url), process_review, dict(title=title, url=url))    next_url = data.xpath('//li[@class="next enable"]//@href').string()    if next_url:        session.queue(Request(next_url), process_revlist, dict())def process_review(data, context, session):    product = Product()    product.name = context['title'].split('- test')[0].split('- pierwsze wrażenia')[0].split('Sprawdzamy ')[-1].split(': Test')[0].split('Test: ')[-1].split('Test -')[-1].split('Test faceta: ')[-1].split('Test Faceta: ')[-1].split('Test ')[-1].replace("Testowałam", "").replace("TEST", "").replace("Recenzja", "").replace("Test", "").replace("[]", "").strip()    product.url = context["url"]    product.ssid = product.url.split(',')[-1]    cat = data.xpath("//div[contains(@class,'article-category')]//text()").string()    if cat and 'test' not in cat.lower() and 'mwc' not in cat.lower():        product.category = cat.strip()    else:        product.category = 'Tech'    review = Review()    review.title = context['title']    review.url = product.url    review.ssid = product.ssid    review.type = "pro"    author = data.xpath('//a[@class="article-author-name"]').first()    if author:        author_name = author.xpath('.//text()').string(multiple=True)        author_url = author.xpath('@href').string()        author_ssid = author_url.split('/')[-1]        if author_name and author_url:            review.authors.append(Person(name=author_name, ssid=author_ssid, profile_url=author_url))        elif author_name:            review.authors.append(Person(name=author_name, ssid=author_name))    date = data.xpath('//meta[@itemprop="datePublished"]/@content').string()    if not date:        date = data.xpath('//script[@type="application/ld+json"][contains(., "datePublished")]/text()').string()    if date:        review.date = date.split('"datePublished":"')[-1].split("T", 1)[0]    if not date:        date = data.xpath("//a[@class='article-date']/@href").string()        if date:            review.date = date.split(",")[-1]    if not date:        date = data.xpath('//span[contains(@class, "date")]/text()').string()        if date:            review.date = date.split(', ')[-1].split(' (')    pros = data.xpath("//ul[@class='embed-gamerank-plus-list']/li")    for pro in pros:        pro = pro.xpath(".//text()").string()        review.add_property(type="pros", value=pro)    cons = data.xpath("//ul[@class='embed-gamerank-minus-list']/li")    for con in cons:        con = con.xpath(".//text()").string()        review.add_property(type="cons", value=con)    conclusion = data.xpath("//div[@class='embed-text-box-text']//text()").string(multiple=True)    if not conclusion:        conclusion = data.xpath("//div[contains(@id,'podsumowanie')]//following-sibling::p[not(@*)][1]//text()").string(multiple=True)    if not conclusion:        conclusion = data.xpath('//p[regexp:test(., "podsumowanie", "i")]//following::p[not(@*)][not(preceding::p[regexp:test(., "specyfikacja techniczna:", "i")] and preceding::p[b[regexp:test(., "specyfikacja techniczna", "i")]])][not(self::p[regexp:test(., "specyfikacja techniczna:", "i")] and self::p[b[regexp:test(., "specyfikacja techniczna", "i")]])][not(contains(., "Korzystanie z portalu oznacza"))][not(preceding::*[contains(., "Korzystanie z portalu oznacza")])]//text()').string(multiple=True)    if not conclusion:        conclusion = data.xpath('//p[regexp:test(., "^podsumowanie", "i")]//text()[not(regexp:test(., "^podsumowanie", "i"))]').string(multiple=True)    if conclusion:        review.add_property(type="conclusion", value=conclusion.strip())    summary = data.xpath("//p[@class='article-lead']//text()").string(multiple=True)    if summary:        review.add_property(type="summary", value=summary.strip())    excerpt = ""    some_text = data.xpath('//body//p[not(@class) and count(./b)<=1 and not(.//a/text()="Regulaminu") and not(contains(text(),"·"))][not(preceding::div[@class="embed-gamerank-details"])][not(contains(., "Cena: "))][not(a[contains(., "Chcesz coś dodać?")])]')    for exc in some_text:        if exc.xpath('self::p[regexp:test(., "specyfikacja techniczna:", "i")] | self::p[b[regexp:test(., "specyfikacja techniczna", "i")]]'):            break        if exc.xpath('self::p[regexp:test(., "podsumowanie", "i")]'):            break        if exc.xpath(".//a//@href") and 'www.facebook.com' in exc.xpath(".//a//@href").string(multiple=True):            continue        if exc.xpath(".//text()"):            excerpt += exc.xpath(".//text()").string(multiple=True)    if excerpt:        if summary:            excerpt = excerpt.replace(summary.strip(), '')        if conclusion:            excerpt = excerpt.replace(conclusion.strip(), '')        review.add_property(type="excerpt", value=excerpt)        product.reviews.append(review)        session.emit(product)