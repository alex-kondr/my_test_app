#TODO: Extract more data when we support for large agents.from agent import *from models.products import *import redebug = Truedef process_category(data, context, session):    for view in data.xpath("//div[@class='product_guide_list_container']/a[contains(@href,'SECTION_ID')]"):         url = view.xpath("(.)/@href").string()          name = view.xpath("(.)//text()[string-length(normalize-space(.))>1]").join("")        if url and name:           session.queue(Request(url), process_category1, {'cat' : name})def process_category1(data, context, session):    cat = context['cat']    for view in data.xpath("//a[@class='rev_name']"):         url = view.xpath("(.)/@href").string()          name = view.xpath("(.)//text()[string-length(normalize-space(.))>1]").join("")        if url and name:           session.queue(Request(url), process_category2, {'cat' : cat + '|' + name})def process_category2(data, context, session):    cat = context['cat']    for view in data.xpath("//a[@class='rev_name']"):         url = view.xpath("(.)/@href").string()          name = view.xpath("(.)/text()[string-length(normalize-space(.))>1]").join("")        if url:           ssid = re_search_once("PRODUCT_ID=(\d+)", url)           session.queue(Request(url), process_product, {'url' : url, 'name' : name, 'cat' : cat, 'ssid' : ssid})def process_product(data, context, session):       product = Product()      product.name =context['name']     product.url = context['url']     product.ssid =context['ssid']     product.category = context['cat']      review = Review()      review.product = product.name       review.url = product.url       review.ssid = product.ssid     review.type = "pro"     review.date = data.xpath("//font[@class='review_date']/text()[string-length(normalize-space(.))>1]").join("")       for list in data.xpath("//table[@class='border']//img[contains(@src, 'jpg')]"):        src = list.xpath("@src").string()        if src:           product.properties.append(ProductProperty(type="image" , value = {'src': src}))    excerpt = data.xpath("//td[@style='padding-left:15px; padding-right:5px;']/text()[string-length(normalize-space(.))>77]").join("")    if excerpt:         review.properties.append(ReviewProperty(type="excerpt", value = excerpt))    i = 0    for grad in data.xpath("//div[@style='float: left;']/img[contains(@src, 'pcm_ful')]"):        val = grad.xpath("@src").string()        if val:           i = i + 1         if i > 0:       review.grades.append(Grade(type='overall', value = i, worst = 0,  best = 5))    pros = data.xpath("//font[preceding-sibling::img[contains(@src, 'pros')]]//text()[string-length(normalize-space(.))>1]").join(" ")    if pros:       review.properties.append(ReviewProperty(type = "pros", value = pros))        cons = data.xpath("//font[preceding-sibling::img[contains(@src, 'cons')]]//text()[string-length(normalize-space(.))>1]").join(" ")    if cons:       review.properties.append(ReviewProperty(type = "cons", value = cons))    con = data.xpath("//a[@class='detail_link'][contains(@href, 'detail')]/@href").string()    if con:       session.do(Request(con), process_con, {'review' : review})    product.reviews.append(review)       session.emit(product)def process_con(data, context, session):    review = context['review']    conc = data.xpath("//td[@style='padding-right:8px;']/text()[string-length(normalize-space(.))>77][last()]").join("")    if conc:         review.properties.append(ReviewProperty(type="conclusion", value = conc))def run(context, session):     session.queue(Request('http://www.pcmag.ru/reviews/'), process_category, {})