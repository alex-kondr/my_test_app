# -*- coding: utf8 -*-from agent import *from models.products import *def run(context, session):    session.sessionbreakers=[SessionBreak(max_requests=10000)]    #session.queue(Request('https://www.polygon.com/archives/reviews/2018/1'), process_years, {})    session.queue(Request('https://www.polygon.com/reviews/archives/'), process_category, {})def process_years(data, context, session):    for link in data.xpath('//div[@class="l-col__sidebar"]//div[contains(@class,"c-filter-list")][1]//li//a'):        url=link.xpath('@href').string()        if url:            session.queue(Request(url),process_months,dict(context))def process_months(data, context, session):    for link in data.xpath('//div[@class="l-col__sidebar"]//div[contains(@class,"c-filter-list")][2]//li//a'):        url=link.xpath('@href').string()        if url:            session.queue(Request(url),process_category,dict(context))def process_category(data, context, session):    for link in data.xpath('//node()[regexp:test(name(),"h\d")][contains(@class,"compact__title")]//a'):        url=link.xpath('@href').string()        name=link.xpath('descendant::text()').string()        if url and name:            session.queue(Request(url),process_product,dict(context,url=url,name=name))    # Next page    next=data.xpath('//a[contains(@class,"pagination__next")]//@href').string()    if next:        session.queue(Request(next), process_category, dict(context))def process_product(data, context, session):    product=Product()    product.name=context['name']    product.url=context['url']    product.ssid=product.name + product.url    # Category    cate_list = [    '//tr[@class="platform"]/td/strong//text()',    '//div[contains(@class,"-platform")]/span[2]//text()']    category = False    for item in cate_list:        category = data.xpath(item).string()        if category:            if ',' in category: category = category.replace(',',' | ')            product.category='Games | ' + category            break    if not category:        product.category='Games'    # Manufacturer    brnd_list = [    '//tr[@class="developer"]/td/strong//text()',    '//div[contains(@class,"-developer")]/span[2]//text()']    for item in brnd_list:        manufacturer = data.xpath(item).string()        if manufacturer:            product.manufacturer=manufacturer            break    review=Review()    review.product=product.name    review.url=product.url    review.type='pro'    review.ssid=product.ssid    # Publish date    review.date = data.xpath("//div[@class='c-byline']//span[@class='c-byline__item'][time]/text()[string-length(normalize-space(.))>0]").string()    if not review.date:        review.date = data.xpath("//div[@class='c-byline']//span[@class='c-byline__item']/time/@datetime").string()    if not review.date:        date_list = [            '//div[@class="header-container"]//p[@class="byline"]//span[@class="timestamp"]//text()',            '//span[descendant::time[@data-ui="timestamp"]]//text()[string-length(normalize-space(.))>1]',            '//node()[@class="byline"][descendant::a[contains(@href,"users/")]]/text()[string-length(normalize-space(.))>2]']        for item in date_list:            pub_date=data.xpath(item).string()            if pub_date:                if 'at' in pub_date: pub_date = pub_date.split('at')[0].replace(',','')[2:]                review.date=pub_date                break    # Author    auth_list = [    '//div[@class="header-container"]//p[@class="byline"]//a//text()',    '//span[@class="c-byline__item"][descendant::a[contains(@href,"users/")]]/a//text()',    '//node()[@class="byline"][descendant::a[contains(@href,"users/")]]/a//text()']    author= False    for item in auth_list:        author=data.xpath(item).string(multiple=True)        if author:            review.authors.append(Person(name=author, ssid=author))            break    if not author:        review.authors.append(Person(name='unknown', ssid='unknown'))    # Grades    s_list = ['//div[@class="review m-review__scores__outercurrent"]/div/div[1]//@class',    '//div[@class="m-review__scores__inner"]/div[1]//@class',    '//div[contains(@class,"--score")]/span[2]//text()']    for item in s_list:        overall=data.xpath(item).string()        if overall:            if ' score_' in overall: overall = float(overall.split(' score_')[1])/10.            review.grades.append(Grade(name='Overall Rating', type='overall', value=overall, best=10))            break    # Excerpt    exce_list = [    '//div[@class="float_wrapper"]//div[contains(@class,"chorus-snippet")]/p//text()',    '//p[contains(@class,"dropcap")]//text()',    '//div[@class="c-entry-content"]//p//text()',    '//p[contains(@class,"body-intro")]//text()']    for item in exce_list:        excerpt=data.xpath(item).string(multiple=True)        if excerpt:            review.properties.append(ReviewProperty(type='excerpt',value=excerpt[:1111]))            break    # Conclusion    conc_list = [    '//div[@class="float_wrapper"]//section[@id="review-wrapup"]/following-sibling::p//text()',    '//node()[regexp:test(name(),"h\d")][regexp:test(descendant::text(),"(Wrap-up)")]/following-sibling::p[not(small)]//text()',    '//div[@class="c-scorecard__additional-info"]//p/text()']    for item in conc_list:        conclusion = data.xpath(item).string(multiple=True)        if conclusion:            review.properties.append(ReviewProperty(type='conclusion', value=conclusion))            break    product.reviews.append(review)    if product.reviews:        session.emit(product)