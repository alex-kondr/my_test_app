from agent import *from models.products import *import reX_REVS = ['https://p3.no/filmpolitiet-dlc', 'https://p3.no/filmpolitiet-podkast/#filmpolitiets-got-pod---episode-4', 'https://p3.no/filmpolitiet/norges-beste-tv-serier-2000-tallet']def remove_emoji(string):    emoji_pattern = re.compile("["                               u"\U0001F600-\U0001F64F"  # emoticons                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs                               u"\U0001F680-\U0001F6FF"  # transport & map symbols                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)                               u"\U00002500-\U00002BEF"  # chinese char                               u"\U00002702-\U000027B0"                               u"\U00002702-\U000027B0"                               u"\U000024C2-\U0001F251"                               u"\U0001f926-\U0001f937"                               u"\U00010000-\U0010ffff"                               u"\u2640-\u2642"                               u"\u2600-\u2B55"                               u"\u200d"                               u"\u23cf"                               u"\u23e9"                               u"\u231a"                               u"\ufe0f"  # dingbats                               u"\u3030"                               "]+", flags=re.UNICODE)    return emoji_pattern.sub(r'', string)def run(context, session):    session.sessionbreakers = [SessionBreak(max_requests=9000)]    session.queue(Request('https://p3.no/category/tv/'), process_revlist, dict(cat='TV-serier'))    session.queue(Request('https://p3.no/category/film/'), process_revlist, dict(cat='Film'))    session.queue(Request('https://p3.no/category/spill/'), process_revlist, dict(cat='Spill'))def process_revlist(data, context, session):    revs = data.xpath('//div[@class="archive-grid"]/h2//a')    for rev in revs:        title = remove_emoji(rev.xpath('text()').string())        url = rev.xpath('@href').string().strip('/')        if 'p3.no' in url and url not in X_REVS:            session.queue(Request(url), process_review, dict(context, title=title, url=url))    next_url = data.xpath('//div[@class="post-previous"]//a/@href').string()    if next_url:        session.queue(Request(next_url), process_revlist, dict(context))def process_review(data, context, session):    if data.xpath('//p//img[contains(@src, "topp_1")]'):        return  # Multi-revs. There full reviews for any product on site    product = Product()    product.name = data.xpath('//li[@class="anmeldertittel"]//text() ').string() or context['title']    product.url = context['url']    product.category = context['cat']    product.ssid = data.xpath('//article[contains(@id, "post-")]/@id').string().split('post-')[-1]    manufacturer = data.xpath('//li[contains(., "Utgiver:")]//text() ').string()    if manufacturer:        product.manufacturer = manufacturer.split('Utgiver:')[-1].strip()    category = context['cat'] + '|'    genres = data.xpath('//li[contains(., "Sjanger:")]/a/text()').strings()    for genre in genres:        genre_name = genre.strip()        if genre_name:            category += genre_name + '/'    product.category = category.strip('|/ ')    review = Review()    review.title = context['title']    review.url = product.url    review.ssid = product.ssid    review.type = 'pro'    date = data.xpath('//div[@class="datometa"]//time/@datetime ').string()    if date:        review.date = date.split('T')[0]    authors = data.xpath('//div[@class="b_skribent"]//a')    for author in authors:        author_name = author.xpath('text()').string()        author_url = author.xpath("@href").string()        if author_name and author_url:            author_ssid = author_url.strip('/').split()[-1]            review.authors.append(Person(name=author_name, ssid=author_ssid))        elif author_name:            review.authors.append(Person(name=author_name, ssid=author_name))    grade_overall = data.xpath('//svg[@class="terning"]/@alt').string()    if grade_overall:        grade_overall = float(grade_overall.split()[-1])        review.grades.append(Grade(type='overall', value=grade_overall, best=6.0))    summary = data.xpath('//div[contains(@class, "entry-excerpt")]/p//text()').string(multiple=True)    if summary:        review.properties.append(ReviewProperty(type='summary', value=summary))    conclusion = data.xpath('//div[@class="entry-content"]/p[preceding-sibling::*[self::h5 or self::h3][regexp:test(.,"Konklusjon")]]//text()').string(multiple=True)    if conclusion:        review.properties.append(ReviewProperty(type='conclusion', value=conclusion))    excerpt = data.xpath('//div[@class="entry-content"]/p[not(preceding-sibling::*[regexp:test(.,"Konklusjon")])][not(contains(., "(Anmeldelsen fortsetter under bildet)") or regexp:test(., "anmeldelse:", "i"))]//text()[not(contains(., "[youtube"))][not(parent::strong) and not(contains(text(), "Spoileradvarsel!"))]').string(multiple=True)    if excerpt:        if conclusion:            excerpt = excerpt.replace(conclusion.strip(), '')        excerpt = remove_emoji(excerpt.encode('utf-8')).strip()        review.properties.append(ReviewProperty(type='excerpt', value=excerpt))        product.reviews.append(review)        session.emit(product)